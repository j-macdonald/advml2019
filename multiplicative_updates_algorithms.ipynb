{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(root='data/CroppedYaleB', reduce=4):\n",
    "    \"\"\" \n",
    "    Load ORL (or Extended YaleB) dataset to numpy array.\n",
    "    \n",
    "    Args:\n",
    "        root: path to dataset.\n",
    "        reduce: scale factor for zooming out images.\n",
    "        \n",
    "    \"\"\" \n",
    "    images, labels = [], []\n",
    "\n",
    "    for i, person in enumerate(sorted(os.listdir(root))):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(root, person)):\n",
    "            continue\n",
    "        \n",
    "        for fname in os.listdir(os.path.join(root, person)):    \n",
    "            \n",
    "            # Remove background images in Extended YaleB dataset.\n",
    "            if fname.endswith('Ambient.pgm'):\n",
    "                continue\n",
    "            \n",
    "            if not fname.endswith('.pgm'):\n",
    "                continue\n",
    "                \n",
    "            # load image.\n",
    "            img = Image.open(os.path.join(root, person, fname))\n",
    "            img = img.convert('L') # grey image.\n",
    "\n",
    "            # reduce computation complexity.\n",
    "            img = img.resize([s//reduce for s in img.size])\n",
    "\n",
    "            # TODO: preprocessing.\n",
    "\n",
    "            # convert image to numpy array.\n",
    "            img = np.asarray(img).reshape((-1,1))\n",
    "\n",
    "            # collect data and label.\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "\n",
    "    # concate all images and labels.\n",
    "    images = np.concatenate(images, axis=1)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ORL dataset.\n",
    "X, Y = load_data(root='data/ORL', reduce=2)\n",
    "print('ORL dataset: X.shape = {}, Y.shape = {}'.format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean multiplicative update alogrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf\n",
    "V = WH\n",
    "\n",
    "W = (n x r) matrix\n",
    "H = (r x m) matrix\n",
    "\n",
    "cost function SSE = sum(V-WH)**2\n",
    "\n",
    "multiplicative update rules\n",
    " H = H*(W.T@V)/(W.T@W@H)\n",
    " W = W(V@H.T)/(W@H@HT)\n",
    " \n",
    " check error\n",
    " \n",
    " itterate\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def euclidean_multiplicative_update (V, r, iteration):\n",
    "    \n",
    "    loss = []\n",
    "    W = np.random.rand(V.shape[0],r)*255\n",
    "    H = np.random.rand(r,V.shape[1])*255\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        H = H*(W.T@V)/(W.T@W@H)\n",
    "        W = W*(V@H.T)/(W@H@H.T)\n",
    "        l = np.sum((V-W@H)**2)\n",
    "        loss.append(l)\n",
    "        \n",
    "    return W, H, loss        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H, loss  = euclidean_multiplicative_update(X, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(loss))\n",
    "plt.plot(range(0,len(loss)),loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf\n",
    "implimentation from page 3 formula 5\n",
    "'''\n",
    "\n",
    "def KL_divergence_update(V,r,iteration):\n",
    "\n",
    "    loss = []\n",
    "    W = np.random.rand(V.shape[0],r)*255\n",
    "    H = np.random.rand(r,V.shape[1])*255\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        H = H * np.dot(W.T,V / np.dot(W,H)) / np.sum(W,0)[:,None]\n",
    "        W = W * np.dot(V / np.dot(W,H),H.T) / np.sum(H,1)\n",
    "        l=np.sum(V*np.log((V++1e-10)/(W@H))-V+(W@H))\n",
    "        loss.append(l)\n",
    "        \n",
    "    return W, H, loss \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, H, loss  = KL_divergence_update(X, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,len(loss)),loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
